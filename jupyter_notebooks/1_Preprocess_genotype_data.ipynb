{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import h5py\n",
    "import tables\n",
    "import glob\n",
    "import itertools\n",
    "import tables\n",
    "import tqdm\n",
    "\n",
    "# fill in the name of your study\n",
    "studyname = \"fill in studyname\"  # fill in the studyname\n",
    "\n",
    "# path were the raw data is (.bim .bam .bed or .vcf)\n",
    "rawpath = \"/home/charlesdarwin/plink/\"    # fill in the path to the plink or vcf files\n",
    "\n",
    "\n",
    "basepath = os.path.dirname(os.getcwd()) + \"/\"\n",
    "hasepath = basepath + \"/hase/\"\n",
    "savepath = basepath + \"/processed_data/\"\n",
    "\n",
    "np.save(savepath + \"studyname.npy\", studyname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/avanhilten/PycharmProjects/GenNet/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run HASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hase is used to convert data to the h5 format for fast reading and loading.\n",
    "# Navigate to directory where you want to install HASE and clone this repository: \n",
    "# git clone https://github.com/roshchupkin/hase.git\n",
    "# More information for conversion can be found here: https://github.com/roshchupkin/hase/wiki/Converting-Data\n",
    "\n",
    "print(\"1. Open a new terminal\")\n",
    "print(\"2. Navigate to the map with hase (i.e. cd /home/charlesdarwin/hase/)\")\n",
    "print(\"\\n\")\n",
    "print(\"3. Run: python hase.py -mode converting -g \"+ rawpath + \" -o \"+hasepath+\"  -study_name \" + studyname)\n",
    "print(\"\\n\")\n",
    "print(\"If the raw data is in vcf format:\")\n",
    "print(\"3. Run: python hase.py -mode converting -g \"+ rawpath + \" -o \"+hasepath+\"  -study_name \" + studyname + \" -vcf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the .h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting with processing... studyname = \", studyname)\n",
    "filepath_hase = hasepath  + '/genotype/{}_'+studyname+'.h5'\n",
    "g=h5py.File(filepath_hase.format(1) ,'r')['genotype']\n",
    "num_pat  = g.shape[1]\n",
    "number_of_files = len(glob.glob(hasepath + \"/genotype/*.h5\"))\n",
    "print('number of files ',number_of_files) \n",
    "\n",
    "\n",
    "f = tables.open_file(savepath + studyname + '_genotype.h5', mode='w')\n",
    "atom = tables.Int8Col()\n",
    "filter_zlib = tables.Filters(complib='zlib', complevel=1)\n",
    "array_c = f.create_earray(f.root, 'data', atom, (0, num_pat), filters=filter_zlib)\n",
    "f.close()\n",
    "\n",
    "print(\"\\n merge all files...\")\n",
    "f = tables.open_file(savepath + studyname + '_genotype.h5', mode='a')\n",
    "for i in tqdm.tqdm(range(number_of_files)): \n",
    "    gen_tmp = h5py.File(filepath_hase.format(i), 'r')['genotype']\n",
    "    f.root.data.append(np.array(np.round(gen_tmp[:,:]), dtype=np.int))\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "t = tables.open_file(savepath + studyname + '_genotype.h5', mode='r')\n",
    "print('merged shape =', t.root.data.shape)\n",
    "num_SNPS = t.root.data.shape[0]\n",
    "\n",
    "p = pd.read_hdf(hasepath + '/probes/' + studyname + \".h5\")\n",
    "print('probe shape =', p.shape)\n",
    "\n",
    "print(\"\\n Impute...\")\n",
    "f = tables.open_file(savepath + studyname + '_genotype_imputed.h5', mode='w')\n",
    "atom = tables.Int8Col()\n",
    "num_pat = t.root.data.shape[1]\n",
    "filter_zlib = tables.Filters(complib='zlib', complevel=1)\n",
    "array_c = f.create_earray(f.root, 'data', atom, (0, num_pat), filters = filter_zlib)\n",
    "f.close()\n",
    "\n",
    "stdSNPs = np.zeros(num_SNPS)\n",
    "f = tables.open_file(savepath + studyname + '_genotype_imputed.h5', mode='a')\n",
    "for i in tqdm.tqdm(range(t.root.data.shape[0])):\n",
    "    d=t.root.data[i,:].astype(\"float32\")\n",
    "    m=np.where(d == 9)\n",
    "    m[0]\n",
    "    d[m] = np.nan\n",
    "    d[m] = np.nanmean(d)\n",
    "    d= d[np.newaxis, :]\n",
    "    f.root.data.append(np.round(d).astype(np.int8))\n",
    "    stdSNPs[i] = np.std(d)\n",
    "f.close()\n",
    "t.close()\n",
    "\n",
    "\n",
    "np.save(savepath + studyname + '_std.npy', stdSNPs)\n",
    "print(\"Continue to 2, shut down this notebook to free up memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
