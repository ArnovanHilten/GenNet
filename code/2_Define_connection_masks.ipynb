{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define Connection Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connectivity Matrices\n",
    "# The connections between the layers are defined by the connectivity matrix.\n",
    "\n",
    "# The matrix has the shape of (N_nodes_layer_1, N_nodes_layer_2).\n",
    "# It is a sparse matrix with zeros for no connections and ones if there is a connections. For example.\n",
    "\n",
    "\n",
    "#             output\n",
    "#           1 2 3 4 5\n",
    "# input 1 | 1 0 0 0 0 |\n",
    "# input 2 | 1 1 0 0 0 |\n",
    "# input 3 | 0 1 0 0 0 |\n",
    "# input 4 | 0 1 0 0 0 |\n",
    "# input 5 | 0 0 1 0 0 |\n",
    "# input 6 | 0 0 0 1 0 |\n",
    "# input 7 | 0 0 0 1 0 |\n",
    "\n",
    "\n",
    "# This connects the first two inputs (1,2) to the first neuron in the second layer.\n",
    "# Connects input 2,3 and 4 to output neuron 2.\n",
    "# Connects input 5 to output neuron 3\n",
    "# Connects input 6 and 7 o the 4th neuron in the subsequent layer\n",
    "# Connects nothing to the 5th neuron\n",
    "\n",
    "#imports & paths\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import h5py\n",
    "import tables\n",
    "from scipy import stats\n",
    "import glob\n",
    "import itertools\n",
    "import tables\n",
    "import tqdm\n",
    "from utils import explode\n",
    "\n",
    "basepath = os.path.dirname(os.getcwd()) + \"/\"\n",
    "hasepath = basepath + \"/hase/\"\n",
    "savepath = basepath + \"/processed_data/\"\n",
    "studyname = str(np.load(savepath + \"studyname.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Input files for Annovar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = pd.read_hdf(hasepath + '/probes/'+studyname+'.h5')\n",
    "print(probes.shape)\n",
    "num_probes = probes.shape[0]\n",
    "probes.head()\n",
    "\n",
    "if os.path.exists(hasepath +'/probes/'+studyname+'_hash_table.csv.gz'):\n",
    "    hashtable = pd.read_csv(hasepath +'/probes/'+studyname+'_hash_table.csv.gz', compression=\"gzip\", sep='\\t')\n",
    "else: \n",
    "    hashtable = pd.read_csv(hasepath +'/probes/'+studyname+'_hash_table.csv', sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "hashtable['allele1']  = hashtable['keys']\n",
    "unhashed_probes = probes.merge(hashtable, on='allele1', how = \"left\" )\n",
    "unhashed_probes = unhashed_probes.drop(columns=[\"keys\", \"allele1\"])\n",
    "unhashed_probes = unhashed_probes.rename(columns = {'allele':'allele1'})\n",
    "\n",
    "#reload hashtable for other allele\n",
    "\n",
    "if os.path.exists(hasepath +'/probes/'+studyname+'_hash_table.csv.gz'):\n",
    "    hashtable = pd.read_csv(hasepath +'/probes/'+studyname+'_hash_table.csv.gz', compression=\"gzip\", sep='\\t')\n",
    "else: \n",
    "    hashtable = pd.read_csv(hasepath +'/probes/'+studyname+'_hash_table.csv', sep='\\t')\n",
    "\n",
    "hashtable['allele2']  = hashtable['keys']\n",
    "unhashed_probes = unhashed_probes.merge(hashtable, on='allele2', how = \"left\")\n",
    "unhashed_probes = unhashed_probes.drop(columns=[\"keys\", \"allele2\"])\n",
    "unhashed_probes = unhashed_probes.rename(columns = {'allele':'allele2'})\n",
    "\n",
    "#clean\n",
    "annovar_input = unhashed_probes.drop(columns=[\"ID\",\"distance\"])\n",
    "annovar_input[\"bp2\"] = annovar_input[\"bp\"]\n",
    "annovar_input[\"index_col\"] = annovar_input.index\n",
    "annovar_input = annovar_input[['CHR', 'bp',\"bp2\",\"allele1\",\"allele2\",\"index_col\"]]\n",
    "\n",
    "print('Number of variants',annovar_input.shape)\n",
    "\n",
    "annovar_input_path = savepath + '/annovar_input_'+studyname+'.csv'\n",
    "annovar_input.to_csv(annovar_input_path,sep=\"\\t\", index=False, header = False)\n",
    "annovar_input.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Annovar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"install annovar: https://doc-openbio.readthedocs.io/projects/annovar/en/latest/user-guide/download/\")\n",
    "print(\"Navigate to annovar, e.g cd /home/charlesdarwin/annovar/\")\n",
    "print(\"Update annovar: annotate_variation.pl -buildver hg19 -downdb -webfrom annovar refGene humandb/\")\n",
    "print(\"Run: perl annotate_variation.pl -geneanno -dbtype refGene -buildver hg19 \"+str(savepath)+\"/annovar_input_\"+str(studyname)+\".csv humandb --outfile \"+str(savepath)+\"/\"+str(studyname)+\"_RefGene\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mask from gene annotations\n",
    "\n",
    "Here we create the mask for the gene layer. Criteria can be set in cell 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annotation = pd.read_csv(savepath +str(studyname)+\"_RefGene.variant_function\",sep='\\t', header=None)\n",
    "print(gene_annotation.shape)\n",
    "gene_annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_annotation.columns = ['into/exonic', 'gene', 'chr', 'bps', 'bpe', \"mutation1\" ,\"mutation2\" ,'index_col']\n",
    "annovar_annotated = annovar_input.merge(gene_annotation[['into/exonic', 'gene',\"index_col\"]], on='index_col', how = \"left\")\n",
    "print(\"Number of Nulls\",annovar_annotated[\"gene\"].isnull().sum())\n",
    "print(\"annotated shape:\",annovar_annotated[\"gene\"].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annovar_annotated[\"snp_std\"] = np.load(savepath + studyname + '_std.npy')\n",
    "annovar_annotated = annovar_annotated.dropna()\n",
    "annovar_annotated =explode(annovar_annotated, [\"gene\"])\n",
    "annovar_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annovar_annotated['dist'] = annovar_annotated['gene'].str.extract(r\"(?<=dist\\=)(.*)(?=\\))\") \n",
    "annovar_annotated['gene'] = annovar_annotated['gene'].str.replace(r\"\\(.*\\)\",\"\",)\n",
    "print(annovar_annotated.shape)\n",
    "annovar_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annovar_annotated.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of None genes:\",sum((annovar_annotated['gene'] != \"NONE\")))\n",
    "print(\"number of unique genes:\",len(gene_annotation[\"gene\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the criteria for connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select annotated, autosomal and SNPs with std > 0. Adjust here if you want to use other criteria.\n",
    "# add here other criteria such as pure exonic, MAF based criteria or distance-based criteria\n",
    "\n",
    "annovar_annotated  = annovar_annotated[(annovar_annotated['gene'] != \"NONE\")\n",
    "                                       & (annovar_annotated['CHR'] < 23)\n",
    "                                       & (annovar_annotated['snp_std'] > 0)]\n",
    "annovar_annotated = annovar_annotated.dropna()\n",
    "print(annovar_annotated.shape)\n",
    "annovar_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = annovar_annotated.drop_duplicates(\"gene\")\n",
    "gene_list[\"gene_id\"] = np.arange(len(gene_list))\n",
    "gene_list = gene_list[[\"gene\",\"gene_id\"]]\n",
    "\n",
    "annovar_annotated = annovar_annotated.merge(gene_list, on=\"gene\")\n",
    "annovar_annotated = annovar_annotated.sort_values(by = \"index_col\", ascending = True)\n",
    "index_list = annovar_annotated.drop_duplicates(\"index_col\")\n",
    "index_list[\"tot_index\"] = np.arange(len(index_list))\n",
    "index_list = index_list[[\"tot_index\",\"index_col\"]]\n",
    "\n",
    "annovar_annotated = annovar_annotated.merge(index_list, on=\"index_col\")\n",
    "annovar_annotated.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Finalize the input by selecting only the relevant inputs and by transposing the data\n",
    "\n",
    "t = tables.open_file(savepath + studyname + '_genotype_imputed.h5', mode='r')\n",
    "data = t.root.data\n",
    "num_pat = data.shape[1]\n",
    "num_feat = data.shape[0]\n",
    "\n",
    "if num_feat != num_probes:\n",
    "    print(\"something went wrong, the sizes do not match\")\n",
    "\n",
    "used_indices = np.zeros(num_feat)\n",
    "used_indices[annovar_annotated[\"index_col\"].unique()]  =1 \n",
    "\n",
    "f = tables.open_file(savepath + studyname + '_genotype_processed.h5', mode='w')\n",
    "array_c = f.create_earray(f.root, 'data', tables.IntCol(), (0,num_feat ), expectedrows=num_pat,filters=tables.Filters(complib='zlib', complevel=1))\n",
    "f.close()\n",
    "\n",
    "f = tables.open_file(savepath + studyname + '_genotype_processed.h5', mode='a')\n",
    "print(\"\\n Finalizing and transposing data...\")\n",
    "for pat in tqdm.tqdm(range(num_pat)):\n",
    "    a = np.transpose(data[:,pat])\n",
    "    a=np.reshape(a, (1,-1))\n",
    "    f.root.data.append(a)\n",
    "    \n",
    "print(\"final shape\",f.root.data.shape)\n",
    "f.close()\n",
    "t.close()\n",
    "print(\"Completed\", studyname)\n",
    "print('file .._genotype.h5 and genotype_imputed.h5 can now be deleted, if you wish to save storage space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask including all variants\n",
    "data = np.ones(len(annovar_annotated), np.bool)\n",
    "coord = ( annovar_annotated[\"tot_index\"].values, annovar_annotated[\"gene_id\"].values )\n",
    "SNP_gene_matrix = scipy.sparse.coo_matrix(((data),coord),  shape = (num_feat, annovar_annotated[\"gene_id\"].max()+1 ))\n",
    "scipy.sparse.save_npz(savepath +'/SNP_gene_mask', SNP_gene_matrix)\n",
    "SNP_gene_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save where the genes end for coloring the plots\n",
    "gene_end = annovar_annotated.groupby(\"CHR\")[\"gene_id\"].max().values\n",
    "gene_end = np.insert(gene_end,0,0)\n",
    "print(gene_end)\n",
    "np.save(savepath + \"gene_end\", gene_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annovar_annotated.to_csv(savepath + 'annovar_annotated.csv', sep=\"\\t\", index=False)\n",
    "gene_overview = annovar_annotated.drop_duplicates(\"gene\")\n",
    "gene_overview.to_csv(savepath + 'gene_overview.csv',sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Continue to the next notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
